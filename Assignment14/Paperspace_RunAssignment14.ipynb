{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Paperspace RunAssignment14.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pasumarthi/EVA/blob/master/Assignment14/Paperspace_RunAssignment14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxk-nDoT5OpC",
        "colab_type": "text"
      },
      "source": [
        "Wrote Custom Momentum\n",
        "used CutOut "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDidBIt0Ccb-",
        "colab_type": "code",
        "outputId": "1306856b-adbe-4ef7-8b74-2ac48fc9d46e",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time, math\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.eager as tfe"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7LBLdFpCccC",
        "colab_type": "code",
        "outputId": "0adc637f-feaa-41b0-ba65-3b7df66c79b6",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug 24 17:45:44 2019       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla V100-SXM2...  On   | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   38C    P0    36W / 300W |     80MiB / 16130MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE0ToBu7CccE",
        "colab_type": "code",
        "outputId": "7567e2a4-0b68-487b-be51-59940a831209",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "multiprocessing.cpu_count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XanMJVrUCccG",
        "colab_type": "code",
        "outputId": "f63ba38f-ce59-4045-c683-179418fee80b",
        "colab": {}
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\r\n",
            "vendor_id\t: GenuineIntel\r\n",
            "cpu family\t: 6\r\n",
            "model\t\t: 79\r\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
            "stepping\t: 0\r\n",
            "microcode\t: 0x1\r\n",
            "cpu MHz\t\t: 2200.000\r\n",
            "cache size\t: 56320 KB\r\n",
            "physical id\t: 0\r\n",
            "siblings\t: 8\r\n",
            "core id\t\t: 0\r\n",
            "cpu cores\t: 4\r\n",
            "apicid\t\t: 0\r\n",
            "initial apicid\t: 0\r\n",
            "fpu\t\t: yes\r\n",
            "fpu_exception\t: yes\r\n",
            "cpuid level\t: 13\r\n",
            "wp\t\t: yes\r\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds\r\n",
            "bogomips\t: 4400.00\r\n",
            "clflush size\t: 64\r\n",
            "cache_alignment\t: 64\r\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\r\n",
            "power management:\r\n",
            "\r\n",
            "processor\t: 1\r\n",
            "vendor_id\t: GenuineIntel\r\n",
            "cpu family\t: 6\r\n",
            "model\t\t: 79\r\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
            "stepping\t: 0\r\n",
            "microcode\t: 0x1\r\n",
            "cpu MHz\t\t: 2200.000\r\n",
            "cache size\t: 56320 KB\r\n",
            "physical id\t: 0\r\n",
            "siblings\t: 8\r\n",
            "core id\t\t: 1\r\n",
            "cpu cores\t: 4\r\n",
            "apicid\t\t: 2\r\n",
            "initial apicid\t: 2\r\n",
            "fpu\t\t: yes\r\n",
            "fpu_exception\t: yes\r\n",
            "cpuid level\t: 13\r\n",
            "wp\t\t: yes\r\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds\r\n",
            "bogomips\t: 4400.00\r\n",
            "clflush size\t: 64\r\n",
            "cache_alignment\t: 64\r\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\r\n",
            "power management:\r\n",
            "\r\n",
            "processor\t: 2\r\n",
            "vendor_id\t: GenuineIntel\r\n",
            "cpu family\t: 6\r\n",
            "model\t\t: 79\r\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
            "stepping\t: 0\r\n",
            "microcode\t: 0x1\r\n",
            "cpu MHz\t\t: 2200.000\r\n",
            "cache size\t: 56320 KB\r\n",
            "physical id\t: 0\r\n",
            "siblings\t: 8\r\n",
            "core id\t\t: 2\r\n",
            "cpu cores\t: 4\r\n",
            "apicid\t\t: 4\r\n",
            "initial apicid\t: 4\r\n",
            "fpu\t\t: yes\r\n",
            "fpu_exception\t: yes\r\n",
            "cpuid level\t: 13\r\n",
            "wp\t\t: yes\r\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds\r\n",
            "bogomips\t: 4400.00\r\n",
            "clflush size\t: 64\r\n",
            "cache_alignment\t: 64\r\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\r\n",
            "power management:\r\n",
            "\r\n",
            "processor\t: 3\r\n",
            "vendor_id\t: GenuineIntel\r\n",
            "cpu family\t: 6\r\n",
            "model\t\t: 79\r\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
            "stepping\t: 0\r\n",
            "microcode\t: 0x1\r\n",
            "cpu MHz\t\t: 2200.000\r\n",
            "cache size\t: 56320 KB\r\n",
            "physical id\t: 0\r\n",
            "siblings\t: 8\r\n",
            "core id\t\t: 3\r\n",
            "cpu cores\t: 4\r\n",
            "apicid\t\t: 6\r\n",
            "initial apicid\t: 6\r\n",
            "fpu\t\t: yes\r\n",
            "fpu_exception\t: yes\r\n",
            "cpuid level\t: 13\r\n",
            "wp\t\t: yes\r\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds\r\n",
            "bogomips\t: 4400.00\r\n",
            "clflush size\t: 64\r\n",
            "cache_alignment\t: 64\r\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\r\n",
            "power management:\r\n",
            "\r\n",
            "processor\t: 4\r\n",
            "vendor_id\t: GenuineIntel\r\n",
            "cpu family\t: 6\r\n",
            "model\t\t: 79\r\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
            "stepping\t: 0\r\n",
            "microcode\t: 0x1\r\n",
            "cpu MHz\t\t: 2200.000\r\n",
            "cache size\t: 56320 KB\r\n",
            "physical id\t: 0\r\n",
            "siblings\t: 8\r\n",
            "core id\t\t: 0\r\n",
            "cpu cores\t: 4\r\n",
            "apicid\t\t: 1\r\n",
            "initial apicid\t: 1\r\n",
            "fpu\t\t: yes\r\n",
            "fpu_exception\t: yes\r\n",
            "cpuid level\t: 13\r\n",
            "wp\t\t: yes\r\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds\r\n",
            "bogomips\t: 4400.00\r\n",
            "clflush size\t: 64\r\n",
            "cache_alignment\t: 64\r\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\r\n",
            "power management:\r\n",
            "\r\n",
            "processor\t: 5\r\n",
            "vendor_id\t: GenuineIntel\r\n",
            "cpu family\t: 6\r\n",
            "model\t\t: 79\r\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
            "stepping\t: 0\r\n",
            "microcode\t: 0x1\r\n",
            "cpu MHz\t\t: 2200.000\r\n",
            "cache size\t: 56320 KB\r\n",
            "physical id\t: 0\r\n",
            "siblings\t: 8\r\n",
            "core id\t\t: 1\r\n",
            "cpu cores\t: 4\r\n",
            "apicid\t\t: 3\r\n",
            "initial apicid\t: 3\r\n",
            "fpu\t\t: yes\r\n",
            "fpu_exception\t: yes\r\n",
            "cpuid level\t: 13\r\n",
            "wp\t\t: yes\r\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds\r\n",
            "bogomips\t: 4400.00\r\n",
            "clflush size\t: 64\r\n",
            "cache_alignment\t: 64\r\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\r\n",
            "power management:\r\n",
            "\r\n",
            "processor\t: 6\r\n",
            "vendor_id\t: GenuineIntel\r\n",
            "cpu family\t: 6\r\n",
            "model\t\t: 79\r\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
            "stepping\t: 0\r\n",
            "microcode\t: 0x1\r\n",
            "cpu MHz\t\t: 2200.000\r\n",
            "cache size\t: 56320 KB\r\n",
            "physical id\t: 0\r\n",
            "siblings\t: 8\r\n",
            "core id\t\t: 2\r\n",
            "cpu cores\t: 4\r\n",
            "apicid\t\t: 5\r\n",
            "initial apicid\t: 5\r\n",
            "fpu\t\t: yes\r\n",
            "fpu_exception\t: yes\r\n",
            "cpuid level\t: 13\r\n",
            "wp\t\t: yes\r\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds\r\n",
            "bogomips\t: 4400.00\r\n",
            "clflush size\t: 64\r\n",
            "cache_alignment\t: 64\r\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\r\n",
            "power management:\r\n",
            "\r\n",
            "processor\t: 7\r\n",
            "vendor_id\t: GenuineIntel\r\n",
            "cpu family\t: 6\r\n",
            "model\t\t: 79\r\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
            "stepping\t: 0\r\n",
            "microcode\t: 0x1\r\n",
            "cpu MHz\t\t: 2200.000\r\n",
            "cache size\t: 56320 KB\r\n",
            "physical id\t: 0\r\n",
            "siblings\t: 8\r\n",
            "core id\t\t: 3\r\n",
            "cpu cores\t: 4\r\n",
            "apicid\t\t: 7\r\n",
            "initial apicid\t: 7\r\n",
            "fpu\t\t: yes\r\n",
            "fpu_exception\t: yes\r\n",
            "cpuid level\t: 13\r\n",
            "wp\t\t: yes\r\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds\r\n",
            "bogomips\t: 4400.00\r\n",
            "clflush size\t: 64\r\n",
            "cache_alignment\t: 64\r\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\r\n",
            "power management:\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n74bx88RCccI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq3lkBgXCccK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 512 #@param {type:\"integer\"}\n",
        "MOMENTUM = 0.9 #@param {type:\"number\"}\n",
        "LEARNING_RATE = 0.4 #@param {type:\"number\"}\n",
        "WEIGHT_DECAY = 5e-4 #@param {type:\"number\"}\n",
        "EPOCHS = 24 #@param {type:\"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMhYgHUpCccM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_pytorch(shape, dtype=tf.float16, partition_info=None):\n",
        "  fan = np.prod(shape[:-1])\n",
        "  bound = 1 / math.sqrt(fan)\n",
        "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPqet80BCccP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBN(tf.keras.Model):\n",
        "  def __init__(self, c_out):\n",
        "    super().__init__()\n",
        "    self.conv = tf.keras.layers.Conv2D(filters=c_out, kernel_size=3, padding=\"SAME\", kernel_initializer=init_pytorch, use_bias=False)\n",
        "    self.bn = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.nn.relu(self.bn(self.conv(inputs)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGRQLXPvCccS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlk(tf.keras.Model):\n",
        "  def __init__(self, c_out, pool, res = False):\n",
        "    super().__init__()\n",
        "    self.conv_bn = ConvBN(c_out)\n",
        "    self.pool = pool\n",
        "    self.res = res\n",
        "    if self.res:\n",
        "      self.res1 = ConvBN(c_out)\n",
        "      self.res2 = ConvBN(c_out)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    h = self.pool(self.conv_bn(inputs))\n",
        "    if self.res:\n",
        "      h = h + self.res2(self.res1(h))\n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WJ2uywsCccW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DavidNet(tf.keras.Model):\n",
        "  def __init__(self, c=64, weight=0.2):\n",
        "    super().__init__()\n",
        "    pool = tf.keras.layers.MaxPooling2D()\n",
        "    self.init_conv_bn = ConvBN(c)\n",
        "    self.blk1 = ResBlk(c*2, pool, res = True)\n",
        "    self.blk2 = ResBlk(c*4, pool)\n",
        "    self.blk3 = ResBlk(c*8, pool, res = True)\n",
        "    self.pool = tf.keras.layers.GlobalMaxPool2D()\n",
        "    self.linear = tf.keras.layers.Dense(10, kernel_initializer=init_pytorch, use_bias=False)\n",
        "    self.weight = weight\n",
        "\n",
        "  def call(self, x, y):\n",
        "    h = self.pool(self.blk3(self.blk2(self.blk1(self.init_conv_bn(x)))))\n",
        "    h = self.linear(h) * self.weight\n",
        "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=h, labels=y)\n",
        "    loss = tf.reduce_sum(ce)\n",
        "    correct = tf.reduce_sum(tf.cast(tf.math.equal(tf.argmax(h, axis = 1), y), tf.float16))\n",
        "    return loss, correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvYf2JHqCccZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "len_train, len_test = len(x_train), len(x_test)\n",
        "\n",
        "num_classes = 10\n",
        "# y_train = tf.keras.utils.to_categorical(y_train, num_classes, dtype='float16')\n",
        "# y_test = tf.keras.utils.to_categorical(y_test, num_classes, dtype='float16')\n",
        "y_train = y_train.astype('int64').reshape(len_train)\n",
        "y_test = y_test.astype('int64').reshape(len_test)\n",
        "\n",
        "train_mean = np.mean(x_train, axis=(0,1,2))\n",
        "train_std = np.std(x_train, axis=(0,1,2))\n",
        "\n",
        "normalize = lambda x: ((x - train_mean) / train_std).astype('float16') # todo: check here\n",
        "pad4 = lambda x: np.pad(x, [(0, 0), (4, 4), (4, 4), (0, 0)], mode='reflect')\n",
        "\n",
        "x_train = normalize(pad4(x_train))\n",
        "x_test = normalize(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRAKBTQqCccb",
        "colab_type": "text"
      },
      "source": [
        "# Cutout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiYLWw3kCccc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_slice(input_: tf.Tensor, replacement, begin) -> tf.Tensor:\n",
        "    inp_shape = tf.shape(input_)\n",
        "    size = tf.shape(replacement)\n",
        "    padding = tf.stack([begin, inp_shape - (begin + size)], axis=1)\n",
        "    replacement_pad = tf.pad(replacement, padding)\n",
        "#     replacement_pad = tf.cast(replacement_pad, dtype=tf.float16)\n",
        "    mask = tf.pad(tf.ones_like(replacement, dtype=tf.bool), padding)\n",
        "    return tf.where(mask, replacement_pad, input_)\n",
        "\n",
        "def cutout(x: tf.Tensor, h: int=8, w: int=8, c: int = 3) -> tf.Tensor:\n",
        "    shape = tf.shape(x)\n",
        "    x0 = tf.random.uniform([], 0, shape[0] + 1 - h, dtype=tf.int32)\n",
        "    y0 = tf.random.uniform([], 0, shape[1] + 1 - w, dtype=tf.int32)\n",
        "    \n",
        "    x = replace_slice(x, tf.zeros([h, w, c], dtype = tf.float16), [x0, y0, 0])\n",
        "#     x = replace_slice(x, tf.constant(1,shape = [h,w,c],dtype = tf.float16)*train_mean, [x0, y0, 0])\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r79tkdTICccf",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuYhCEKGCccf",
        "colab_type": "text"
      },
      "source": [
        "# With\n",
        "lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//5, 21, EPOCHS], [0, LEARNING_RATE,0.021, 0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r6b70_2Cccg",
        "colab_type": "code",
        "outputId": "067a2d02-9fed-4370-d71c-1e9a406dab52",
        "colab": {}
      },
      "source": [
        "model = DavidNet()\n",
        "#model.summary()\n",
        "batches_per_epoch = len_train//BATCH_SIZE + 1\n",
        "# LEARNING_RATE=0.4\n",
        "lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//5, 21, EPOCHS], [0, LEARNING_RATE,0.021, 0])[0]\n",
        "global_step = tf.train.get_or_create_global_step()\n",
        "lr_func = lambda: lr_schedule(global_step/batches_per_epoch)/BATCH_SIZE\n",
        "# opt = tf.train.MomentumOptimizer(lr_func, momentum=MOMENTUM, use_nesterov=True)\n",
        "data_aug = lambda x, y: (cutout(tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3]))), y)\n",
        "\n",
        "\n",
        "t = time.time()\n",
        "test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
        "\n",
        "mom_state = {}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss = test_loss = train_acc = test_acc = 0.0\n",
        "  train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(data_aug, num_parallel_calls=8).shuffle(len_train).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "  tf.keras.backend.set_learning_phase(1)\n",
        "#   for (x, y) in tqdm(train_set):\n",
        "  for (x, y) in train_set:\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss, correct = model(x, y)\n",
        "\n",
        "    var = model.trainable_variables\n",
        "    grads = tape.gradient(loss, var)\n",
        "    \n",
        "    global_step.assign_add(1)\n",
        "    lr = lr_func()\n",
        "\n",
        "    for g, v in zip(grads, var):\n",
        "      g += v * WEIGHT_DECAY * BATCH_SIZE\n",
        "      \n",
        "      if v not in mom_state:\n",
        "        state = tf.zeros_like(g)\n",
        "      else:\n",
        "        state = mom_state[v]\n",
        "        \n",
        "      state = state * MOMENTUM + g\n",
        "      g += state * MOMENTUM\n",
        "      v.assign_add(g * (-lr))\n",
        "      mom_state[v] = state\n",
        "\n",
        "#     opt.apply_gradients(zip(grads, var), global_step=global_step)\n",
        "\n",
        "    train_loss += loss.numpy()\n",
        "    train_acc += correct.numpy()\n",
        "\n",
        "  tf.keras.backend.set_learning_phase(0)\n",
        "  for (x, y) in test_set:\n",
        "    loss, correct = model(x, y)\n",
        "    test_loss += loss.numpy()\n",
        "    test_acc += correct.numpy()\n",
        "    \n",
        "  print('epoch:', epoch+1, 'lr:', lr_schedule(epoch+1), 'train loss:', train_loss / len_train, 'train acc:', train_acc / len_train, 'val loss:', test_loss / len_test, 'val acc:', test_acc / len_test, 'time:', time.time() - t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0824 17:45:55.403690 140525221713728 deprecation.py:323] From <ipython-input-12-c9dc21f47e08>:8: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 lr: 0.08 train loss: 1.538935 train acc: 0.44014 val loss: 1.2504 val acc: 0.5856 time: 17.21765923500061\n",
            "epoch: 2 lr: 0.16 train loss: 0.99907 train acc: 0.64874 val loss: 1.056825 val acc: 0.6439 time: 29.396451234817505\n",
            "epoch: 3 lr: 0.24 train loss: 0.793065 train acc: 0.72694 val loss: 1.076775 val acc: 0.6747 time: 41.439059257507324\n",
            "epoch: 4 lr: 0.32 train loss: 0.659765 train acc: 0.77282 val loss: 0.900975 val acc: 0.7148 time: 53.11166858673096\n",
            "epoch: 5 lr: 0.4 train loss: 0.576995 train acc: 0.79802 val loss: 0.7360625 val acc: 0.7521 time: 64.86671018600464\n",
            "epoch: 6 lr: 0.37631250000000005 train loss: 0.500575 train acc: 0.82768 val loss: 0.55155 val acc: 0.8086 time: 76.6717689037323\n",
            "epoch: 7 lr: 0.352625 train loss: 0.44165 train acc: 0.84704 val loss: 0.6141125 val acc: 0.7959 time: 88.26883912086487\n",
            "epoch: 8 lr: 0.3289375 train loss: 0.4107225 train acc: 0.85878 val loss: 0.5123 val acc: 0.8252 time: 100.2941381931305\n",
            "epoch: 9 lr: 0.30525 train loss: 0.37867 train acc: 0.86958 val loss: 0.4385625 val acc: 0.852 time: 112.05120992660522\n",
            "epoch: 10 lr: 0.28156250000000005 train loss: 0.35942 train acc: 0.87542 val loss: 0.61345 val acc: 0.7917 time: 123.67095065116882\n",
            "epoch: 11 lr: 0.257875 train loss: 0.34045375 train acc: 0.8842 val loss: 0.3997875 val acc: 0.863 time: 135.4792079925537\n",
            "epoch: 12 lr: 0.23418750000000002 train loss: 0.31103625 train acc: 0.89316 val loss: 0.40645 val acc: 0.8658 time: 147.16503024101257\n",
            "epoch: 13 lr: 0.21050000000000002 train loss: 0.29061125 train acc: 0.90006 val loss: 0.3744 val acc: 0.8739 time: 159.04096722602844\n",
            "epoch: 14 lr: 0.18681250000000002 train loss: 0.272395 train acc: 0.90574 val loss: 0.39021875 val acc: 0.8681 time: 170.90336322784424\n",
            "epoch: 15 lr: 0.16312500000000002 train loss: 0.25132 train acc: 0.91186 val loss: 0.4872375 val acc: 0.8395 time: 182.93435883522034\n",
            "epoch: 16 lr: 0.1394375 train loss: 0.22965875 train acc: 0.92186 val loss: 0.43638125 val acc: 0.8553 time: 194.8295657634735\n",
            "epoch: 17 lr: 0.11575000000000002 train loss: 0.204079375 train acc: 0.93002 val loss: 0.3266 val acc: 0.8911 time: 206.72693610191345\n",
            "epoch: 18 lr: 0.09206250000000005 train loss: 0.175188125 train acc: 0.94218 val loss: 0.318125 val acc: 0.8932 time: 218.44927191734314\n",
            "epoch: 19 lr: 0.06837500000000002 train loss: 0.1478375 train acc: 0.95122 val loss: 0.25701875 val acc: 0.9143 time: 230.1474552154541\n",
            "epoch: 20 lr: 0.04468749999999999 train loss: 0.118089375 train acc: 0.96166 val loss: 0.29724375 val acc: 0.9039 time: 242.1692807674408\n",
            "epoch: 21 lr: 0.021 train loss: 0.0966659375 train acc: 0.97032 val loss: 0.199134375 val acc: 0.9346 time: 254.6014904975891\n",
            "epoch: 22 lr: 0.014000000000000002 train loss: 0.0771359375 train acc: 0.97674 val loss: 0.1883 val acc: 0.9396 time: 267.16229701042175\n",
            "epoch: 23 lr: 0.007000000000000001 train loss: 0.071721875 train acc: 0.97934 val loss: 0.185525 val acc: 0.94 time: 279.6129050254822\n",
            "epoch: 24 lr: 0.0 train loss: 0.0656475 train acc: 0.98078 val loss: 0.1839625 val acc: 0.9408 time: 292.1171534061432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLLKSKttCcch",
        "colab_type": "text"
      },
      "source": [
        "# With \n",
        "\n",
        "lambda t: np.interp([t], [0, (EPOCHS+1)//6, 20, EPOCHS], [0, LEARNING_RATE,0.021, 0])[0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cWgp5MRCcci",
        "colab_type": "code",
        "outputId": "968badc8-b84f-4299-dceb-9037a3111d46",
        "colab": {}
      },
      "source": [
        "model = DavidNet()\n",
        "#model.summary()\n",
        "batches_per_epoch = len_train//BATCH_SIZE + 1\n",
        "# LEARNING_RATE=0.4\n",
        "lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//6, 20, EPOCHS], [0, LEARNING_RATE,0.021, 0])[0]\n",
        "global_step = tf.train.get_or_create_global_step()\n",
        "lr_func = lambda: lr_schedule(global_step/batches_per_epoch)/BATCH_SIZE\n",
        "# opt = tf.train.MomentumOptimizer(lr_func, momentum=MOMENTUM, use_nesterov=True)\n",
        "data_aug = lambda x, y: (cutout(tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3]))), y)\n",
        "\n",
        "\n",
        "t = time.time()\n",
        "test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
        "\n",
        "mom_state = {}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss = test_loss = train_acc = test_acc = 0.0\n",
        "  train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(data_aug, num_parallel_calls=8).shuffle(len_train).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "  tf.keras.backend.set_learning_phase(1)\n",
        "#   for (x, y) in tqdm(train_set):\n",
        "  for (x, y) in train_set:\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss, correct = model(x, y)\n",
        "\n",
        "    var = model.trainable_variables\n",
        "    grads = tape.gradient(loss, var)\n",
        "    \n",
        "    global_step.assign_add(1)\n",
        "    lr = lr_func()\n",
        "\n",
        "    for g, v in zip(grads, var):\n",
        "      g += v * WEIGHT_DECAY * BATCH_SIZE\n",
        "      \n",
        "      if v not in mom_state:\n",
        "        state = tf.zeros_like(g)\n",
        "      else:\n",
        "        state = mom_state[v]\n",
        "        \n",
        "      state = state * MOMENTUM + g\n",
        "      g += state * MOMENTUM\n",
        "      v.assign_add(g * (-lr))\n",
        "      mom_state[v] = state\n",
        "\n",
        "#     opt.apply_gradients(zip(grads, var), global_step=global_step)\n",
        "\n",
        "    train_loss += loss.numpy()\n",
        "    train_acc += correct.numpy()\n",
        "\n",
        "  tf.keras.backend.set_learning_phase(0)\n",
        "  for (x, y) in test_set:\n",
        "    loss, correct = model(x, y)\n",
        "    test_loss += loss.numpy()\n",
        "    test_acc += correct.numpy()\n",
        "    \n",
        "  print('epoch:', epoch+1, 'lr:', lr_schedule(epoch+1), 'train loss:', train_loss / len_train, 'train acc:', train_acc / len_train, 'val loss:', test_loss / len_test, 'val acc:', test_acc / len_test, 'time:', time.time() - t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0824 17:39:07.683829 140270087657280 deprecation.py:323] From <ipython-input-12-c9dc21f47e08>:8: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 lr: 0.1 train loss: 1.534265 train acc: 0.44332 val loss: 1.415625 val acc: 0.522 time: 17.10179090499878\n",
            "epoch: 2 lr: 0.2 train loss: 1.03221 train acc: 0.64348 val loss: 0.837475 val acc: 0.7227 time: 28.305668354034424\n",
            "epoch: 3 lr: 0.30000000000000004 train loss: 0.793585 train acc: 0.72636 val loss: 0.69685 val acc: 0.7539 time: 39.454989194869995\n",
            "epoch: 4 lr: 0.4 train loss: 0.6462125 train acc: 0.77516 val loss: 0.7458875 val acc: 0.7508 time: 50.7466676235199\n",
            "epoch: 5 lr: 0.37631250000000005 train loss: 0.54535 train acc: 0.81126 val loss: 0.61495 val acc: 0.7884 time: 61.869755029678345\n",
            "epoch: 6 lr: 0.352625 train loss: 0.4680375 train acc: 0.83882 val loss: 0.7017 val acc: 0.7705 time: 72.91537952423096\n",
            "epoch: 7 lr: 0.3289375 train loss: 0.42863 train acc: 0.85296 val loss: 0.5993125 val acc: 0.7956 time: 84.08523869514465\n",
            "epoch: 8 lr: 0.30525 train loss: 0.395945 train acc: 0.86296 val loss: 0.5220875 val acc: 0.8291 time: 95.1531491279602\n",
            "epoch: 9 lr: 0.28156250000000005 train loss: 0.36990375 train acc: 0.87344 val loss: 0.5861375 val acc: 0.8019 time: 106.1741418838501\n",
            "epoch: 10 lr: 0.257875 train loss: 0.34528625 train acc: 0.88192 val loss: 0.4511625 val acc: 0.8515 time: 117.37058210372925\n",
            "epoch: 11 lr: 0.23418750000000002 train loss: 0.327355 train acc: 0.88858 val loss: 0.42645 val acc: 0.8582 time: 128.82784938812256\n",
            "epoch: 12 lr: 0.21050000000000002 train loss: 0.29874125 train acc: 0.89618 val loss: 0.39121875 val acc: 0.8684 time: 140.44537782669067\n",
            "epoch: 13 lr: 0.18681250000000002 train loss: 0.2757525 train acc: 0.90668 val loss: 0.48055 val acc: 0.8362 time: 151.86621022224426\n",
            "epoch: 14 lr: 0.16312500000000002 train loss: 0.25226625 train acc: 0.91398 val loss: 0.40905 val acc: 0.8694 time: 163.08275508880615\n",
            "epoch: 15 lr: 0.1394375 train loss: 0.23440375 train acc: 0.91958 val loss: 0.42345 val acc: 0.8624 time: 174.57854914665222\n",
            "epoch: 16 lr: 0.11575000000000002 train loss: 0.208065 train acc: 0.92868 val loss: 0.30116875 val acc: 0.8974 time: 186.10116624832153\n",
            "epoch: 17 lr: 0.09206250000000005 train loss: 0.18286375 train acc: 0.93796 val loss: 0.34031875 val acc: 0.8901 time: 197.55140566825867\n",
            "epoch: 18 lr: 0.06837500000000002 train loss: 0.154963125 train acc: 0.9481 val loss: 0.26641875 val acc: 0.9114 time: 209.39466190338135\n",
            "epoch: 19 lr: 0.04468749999999999 train loss: 0.126776875 train acc: 0.9589 val loss: 0.241396875 val acc: 0.9218 time: 220.70636248588562\n",
            "epoch: 20 lr: 0.021 train loss: 0.09986125 train acc: 0.96846 val loss: 0.2214625 val acc: 0.9299 time: 232.1088469028473\n",
            "epoch: 21 lr: 0.01575 train loss: 0.082265625 train acc: 0.97482 val loss: 0.206053125 val acc: 0.9339 time: 243.30148673057556\n",
            "epoch: 22 lr: 0.0105 train loss: 0.073235 train acc: 0.97794 val loss: 0.202628125 val acc: 0.9348 time: 254.80492210388184\n",
            "epoch: 23 lr: 0.005250000000000001 train loss: 0.0666115625 train acc: 0.98138 val loss: 0.19825625 val acc: 0.9358 time: 266.33833479881287\n",
            "epoch: 24 lr: 0.0 train loss: 0.0627615625 train acc: 0.98268 val loss: 0.19750625 val acc: 0.937 time: 277.85442543029785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGQ9BLOMCcck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}